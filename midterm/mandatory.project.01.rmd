---
title: "Data Science for Bioinformatics"
output: html_document
editor_options: 
  chunk_output_type: console
---


# Midterm project on "Drosophila melanogaster Genetic Reference Panel""

Reference paper describes the data obtained here. 

Paper source: The Drosophila melanogaster Genetic Reference Panel, Nature 2012

Data source  

 * http://dgrp2.gnets.ncsu.edu/  (the project)
 * http://dgrp2.gnets.ncsu.edu/data.html  (the data source tabular 3)
 
Tabular formatted genotype (space delimited, 0 = ref allele, 2 = alt allele (not necessarily minor), - = missing)

A zipped version of the data is available in the datasets folder.

Unzipped it is about 2 gigabytes and will probably be too large for your computers memory.

But for speed we recommend that you unzip the data - then work on the unzipped data file!

# Questions on the DRGP dataset

## For the entire report we only focus on variants located on chromosome 3L.

#### Q: Unzip the data, extract all variants located on the chromosome and save the data (write_rds)

Comment out during kniting to make it faster.
```

library(tidyverse)

# The file is already unzipped.
# unzip(zipfile = "../datasets/dataset.02.dgrp2.tgeno.zip", overwrite = T)

f <- function(df, pos) {
  #print(df)
  
  tt <- df %>% 
    select(-c(starts_with('line'))) %>%
    filter(chr == '3L') %>%
    {.}
  #write_csv(tt, "../datasets/dgrp2.3L", append = TRUE) # Log progress to log file
  
  return(tt)
}

data_file_path = "../datasets/dgrp2.tgeno"

first_2 = read_delim(data_file_path, delim = ' ', n_max = 2)

df_ <- read_delim_chunked(file = data_file_path, 
                         callback = ListCallback$new(f), 
                         chunk_size = 50000, guess_max = 100,
                         col_names = T, delim = " ", comment = "#",
                         progress = T)
data_3L = bind_rows(df_)

data_3L = data_3L %>% mutate(
  total_l = 205
)
```



#### Q: How many variants do you have ?


```{r}
summary(data_3L)
```

A: 1001554

#### Q: Report how many variants have less than 90% of the lines genotyped.


```{r}

genotyped_data = data_3L %>%
  mutate(genotyped_p = (refc + altc) / total_l)

count(genotyped_data, genotyped_p < 0.9)
```


#### Q: Report how many variants have less than 95% of the lines genotyped.

```{r}
count(genotyped_data, genotyped_p < 0.95)
```

#### Q: Extract variants that are genotyped in at least 95% of the lines.

```{r}
genotyped_95 = genotyped_data %>% filter(genotyped_p >= 0.95)
```

#### Q: Visualize the distribution of variant minor allele frequencies

```{r}
maf_per_variant =  data_3L %>% 
  mutate(maf = altc / total_l)

ggplot(maf_per_variant, aes(maf)) + geom_density()

```

#### Q: Visualize how the maf changes along the chromosome position

```{r}
maf_per_pos = maf_per_variant %>%
  group_by(pos) %>%
  summarise(maf = mean(maf))

bucket_cov = 10^5

binned_maf_per_pos = maf_per_pos %>%
  mutate(bucket = bucket_cov * pos%/%bucket_cov) %>%
  group_by(bucket) %>%
  summarise(maf = mean(maf))

ggplot(binned_maf_per_pos, aes(x = bucket, y = maf)) + geom_line()
```


#### Q: Visualize the distribution of coverage of variants ("cov") that are genotyped in at least 95% of the lines

```{r}
ggplot(genotyped_95, aes(cov)) + geom_density()
```


#### Q: Visualize how the coverage changes along the chromosome position

```{r}

bucket_cov = 10^5

cov_per_pos = data_3L %>%
  mutate(bucket = bucket_cov * pos%/%bucket_cov) %>%
  group_by(bucket) %>%
  summarise(cov_l = mean(cov))

ggplot(cov_per_pos, aes(x = bucket, y = cov_l)) + geom_line()
```

#### Q: How many loci are there of each type of variant in your dataset?

HINT: ?stringr::str_split_fixed and look at the "id" column

These are the variant types:
INSertions, DELetions, Multiple Nucleotide Polymorphism, Single Nucleotide Polymorphism


```{r}
data_3L_varc = data_3L
data_3L_varc['var_class'] = str_split_fixed(data_3L['id'][[1]], "_", 3)[,3]

data_3L_varc %>%
  group_by(var_class) %>%
  summarise(n_loci = length(unique(pos)))
```

#### Q: How many rare and common variants are there?

We define a variant as either rare (minor allele frequency < 0.05) or common (minor allele frequency >= 0.05).

```{r}
maf_per_variant %>% count(maf < 0.05)
```

#### Q: Is there a statistical association between the different types of variants and the rare/common variants?

Do you think one of the variant classes have more rare alleles than other classes?

A:
For each variant class VC:
  H0: VC does not have more rare alleles than other classes
  HA: 'GREATER': VC has more alleles than other classes.

```{r}
data_3L_varc['maf'] = maf_per_variant['maf']
pval_res = data_3L_varc %>%
  group_by(var_class) %>%
  summarise(vc = var_class[1],
            vc_rare = length(maf[maf<0.05]),
            vc_total = length(maf),
            other_rare = length((data_3L_varc %>% filter(var_class != vc & maf < 0.05))$maf),
            other_total = length((data_3L_varc %>% filter(var_class != vc))$maf),
            probr_vc = vc_rare / vc_total,
            probr_other = other_rare / other_total,
            p_value = binom.test(vc_rare, vc_total, p = probr_other, alternative = 'greater')[['p.value']])
```
A: We can see that INS and SNP are the ones that fit the null hypothesis. Del and MNP have more lower alleles:
```{r}
data.frame(pval_res$vc, pval_res$p_value)
```


#### Q: If coverage was homogenous throughout the genome (by that we mean that on average the coverage is the same for any given position), what probability distribution is expected to capture well the coverage? 
Poisson distribution

#### Q: Make goodness of fit test of the coverage data of your variants on chromosome 3L: is the theoretical distribution you just proposed a good fit for the data?

```{r}
cov_freq = data_3L %>% group_by(cov) %>% summarise(obs = n())

total_cov = sum(cov_freq$obs)
mean_cov = sum(cov_freq$cov * cov_freq$obs) / total_cov

observed_cp = cov_freq$obs
expected_cp = dpois(cov_freq$cov, mean_cov)

tbl = tibble(observed_cp, expected_cp)

chisq.test(tbl, correct = FALSE)
```
Yes. Aparently the poison distribution is a pretty good match for our data, given the result of the chisq test.

# From now on you should focus on a smaller region of chromosome 3L

#### Q: Pick a starting point on chromosome 3L and extract/slice 20000 SNPs downstream of that position. What is the range of the positions?

So only pick 20000 SNPS. Ignore INSertions, DELetions, and MNPs.


The following part has been commented out during kniting, to make it faster.

```

f <- function(df, pos) {
  tt <- df %>% filter(chr == '3L') %>% {.}
  
  tt['var_class'] = str_split_fixed(tt['id'][[1]], "_", 3)[,3]
  tt_res = tt %>% filter(var_class == 'SNP')
  return(tt_res)
}

data_file_path = "../datasets/dgrp2.tgeno"

df_2 <- read_delim_chunked(file = data_file_path, 
                         callback = ListCallback$new(f), 
                         chunk_size = 50000, guess_max = 100,
                         col_names = T, delim = " ", comment = "#",
                         progress = T)
```

#### Q: Pick a starting point on chromosome 3L and extract/slice 20000 SNPs downstream of that position. What is the range of the positions?
```{r}
df <- bind_rows(df_2)
start <- length(df$pos) - 25000

snps_3L <- slice(df, start:(start+20000) )  %>%
  gather(key = "line", value = "genotype", starts_with("line")) %>%
  filter(genotype != '-')
summary(snps_3L$pos)
```


#### Q: Calculate the r squared association between each pair of neighboring SNPS (this association is also called "linkage disequilibrium")

In population genetics, linkage disequilibrium is the non-random association of alleles at different loci in a given population.

Loci are said to be in linkage disequilibrium when the frequency of association of their different alleles is higher or lower than what would be expected if the loci were independent and associated randomly.

You should calculate the $r^2$ measure of linkage disequilibrium, which is defined as:

\begin{equation}

r^2(p_a,p_b,p_{ab}) = \frac{(p_{ab}−p_a \cdot p_b)^2}{ p_a \cdot (1−p_a) \cdot p_b\cdot(1−p_b)}

\end{equation}

where $p_a$ is the frequency of allele $a$ at locus 1, $p_b$ is the frequency of allele $b$ at locus 2 and $p_{ab}$ is the frequency of haplotypes having allele $a$ at locus 1 and allele $b$ at locus 2 (Hill & Robertson, 1968).

Read more at wikipedia (if you like).

HINT: ?lead, tidy data
HINT: only use cases where both SNPs are genotyped in the line (i.e. 0 or 2)

```
# A tibble: 3,953,818 x 14
   chr      pos id            ref   alt    refc  altc  qual   cov snptype line     genotype genotype2 haplotype
   <chr>  <int> <chr>         <chr> <chr> <int> <int> <int> <int> <chr>   <chr>    <chr>    <chr>     <chr>    
 1 3L    100250 3L_100250_SNP A     G       179    14   999    24 SNP     line_100 0        0         0 0      
 2 3L    100256 3L_100256_SNP A     C       202     3   999    24 SNP     line_100 0        0         0 0      
 3 3L    100274 3L_100274_SNP G     T       184    16   999    24 SNP     line_100 0        0         0 0      
 4 3L    100365 3L_100365_SNP C     A       203     1   999    30 SNP     line_100 0        0         0 0      
 5 3L    100424 3L_100424_SNP T     A       204     1   999    31 SNP     line_100 0        0         0 0      
 6 3L    100626 3L_100626_SNP A     T       204     1   999    35 SNP     line_100 0        2         0 2      
 7 3L    100728 3L_100728_SNP T     A        78   123   999    33 SNP     line_100 2        0         2 0      
 8 3L    100731 3L_100731_SNP C     A       203     2   999    34 SNP     line_100 0        0         0 0      
 9 3L    100858 3L_100858_SNP C     G       203     1   999    32 SNP     line_100 0        0         0 0      
10 3L    100876 3L_100876_SNP G     C       204     1   999    31 SNP     line_100 0        0         0 0      
# ... with 3,953,808 more rows

```
```{r}

r2_summ = snps_3L %>% 
  arrange(line, pos) %>%
  mutate(
    bp = lead(pos) - pos,
    genotype2 = lead(genotype, 1), 
    haplotype = paste(genotype, genotype2)) %>% 
  drop_na()  %>%
  group_by(pos) %>%
  summarise(
    bp = mean(bp),
    p0 = length(genotype[genotype == '0'])/length(genotype),
    p2 = length(genotype2[genotype2 == '2'])/length(genotype2),
    p02 = length(haplotype[haplotype == '0 2'])/length(haplotype),
    r2 = ((p02 - (p0 * p2))^2) / (p0*(1-p0)*p2*(1-p2))
  ) %>%
  filter(!is.na(r2))
```

#### Q: Summarize average LD in distance bins and visualize how LD varies with the physical distance beween SNPs (measured in bp)

HINT: 

```

dist <- 1:200
ifelse(dist > 10, 5 + 10 * dist %/% 10, dist )

```

```{r}

smoothing = 1000
mid = smoothing / 2

r2_vs_dist = r2_summ %>%
  mutate(bpg = mid + smoothing * bp %/% smoothing) %>%
  group_by(bpg) %>%
  summarise(r2g = mean(r2))

ggplot(r2_vs_dist, aes(x = log2(bpg), y = r2g)) + geom_point()

```

#### Q: Compare and discuss with the Fig 1 of the paper.
The results depend a lot on the positions that you get. Usually r2 decreases with the distance between positions, but not for each specific case. If we bin the distances in large enough bins, then we see a general decrease. 

If however, we would run this on all of our data (like in the paper), we would obtain similar results to what the authors have.
